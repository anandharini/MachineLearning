{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e23c49-dd83-4905-99fa-c3761b5df042",
   "metadata": {},
   "source": [
    "# Conditional WGAN-GP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb7e0c4-8bf2-47ff-af8d-2d9295088bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:06:35.259752: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 20:06:36.025019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    ")\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0c3207-fca7-4655-b175-15343cb94826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "CLASSES = 2\n",
    "BATCH_SIZE = 128\n",
    "Z_DIM = 32\n",
    "LEARNING_RATE = 0.00005\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "EPOCHS = 20\n",
    "CRITIC_STEPS = 3\n",
    "GP_WEIGHT = 10.0\n",
    "LOAD_MODEL = False\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "LABEL = \"Blond_Hair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4963fe4e-6c59-4af0-991f-af3e4132073e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
      "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
      "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
      "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
      "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
      "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
      "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
      "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
      "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
      "       'Wearing_Necktie', 'Young'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                -1                1           1               -1   \n",
       "1  000002.jpg                -1               -1          -1                1   \n",
       "2  000003.jpg                -1               -1          -1               -1   \n",
       "3  000004.jpg                -1               -1           1               -1   \n",
       "4  000005.jpg                -1                1           1               -1   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n",
       "0    -1     -1        -1        -1          -1  ...         -1        1   \n",
       "1    -1     -1        -1         1          -1  ...         -1        1   \n",
       "2    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "3    -1     -1        -1        -1          -1  ...         -1       -1   \n",
       "4    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1         -1                 1           -1                 1   \n",
       "1             -1         -1                -1           -1                -1   \n",
       "2             -1          1                -1           -1                -1   \n",
       "3              1         -1                 1           -1                 1   \n",
       "4             -1         -1                -1           -1                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                -1               -1      1  \n",
       "1                -1               -1      1  \n",
       "2                -1               -1      1  \n",
       "3                 1               -1      1  \n",
       "4                -1               -1      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = pd.read_csv(\"/home/ec2-user/SageMaker/MachineLearning/data/celeba-dataset/list_attr_celeba.csv\")\n",
    "print(attributes.columns)\n",
    "attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c5e0d22-4bbb-4148-af0f-05ffdeb39171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -1\n",
       "1        -1\n",
       "2        -1\n",
       "3        -1\n",
       "4        -1\n",
       "         ..\n",
       "202594    1\n",
       "202595    1\n",
       "202596   -1\n",
       "202597   -1\n",
       "202598    1\n",
       "Name: Blond_Hair, Length: 202599, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caabd9bb-8bb8-412f-9f71-f77544ecfe32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "labels = attributes[LABEL].tolist()\n",
    "int_labels = [x if x == 1 else 0 for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45f61ac-d209-4e23-bab3-32114c0e8e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:06:43.139296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "    \"/home/ec2-user/SageMaker/MachineLearning/data/celeba-dataset/img_align_celeba\",\n",
    "    labels=int_labels,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad399cc1-7eca-4027-9df8-529aaed81c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    Normalize and reshape the images\n",
    "    \"\"\"\n",
    "    img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "\n",
    "train = train_data.map(\n",
    "    lambda x, y: (preprocess(x), tf.one_hot(y, depth=CLASSES))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c4b9b-3202-4e61-9826-ae369d276a17",
   "metadata": {},
   "source": [
    "# Build the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0562a65c-47d7-4fb9-a18f-0cbcb136ec5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 64, 64, 2)]          0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 64, 5)            0         ['input_1[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)           5184      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)           0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)          131200    ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)          0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16, 16, 128)          0         ['leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)            262272    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)            0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 8, 8, 128)            0         ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)            262272    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 128)            0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)            0         ['leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 1, 1, 1)              2049      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1)                    0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 662977 (2.53 MB)\n",
      "Trainable params: 662977 (2.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "label_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CLASSES))\n",
    "x = layers.Concatenate(axis=-1)([critic_input, label_input])\n",
    "x = layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(1, kernel_size=4, strides=1, padding=\"valid\")(x)\n",
    "critic_output = layers.Flatten()(x)\n",
    "\n",
    "critic = models.Model([critic_input, label_input], critic_output)\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02628aa-a5e4-4aba-afd6-a29601229f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 34)                   0         ['input_3[0][0]',             \n",
      " )                                                                   'input_4[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 34)             0         ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 4, 4, 128)            69632     ['reshape[0][0]']             \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 4, 4, 128)            512       ['conv2d_transpose[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4, 4, 128)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 8, 8, 128)            262144    ['leaky_re_lu_4[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 128)            512       ['conv2d_transpose_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 8, 8, 128)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 16, 16, 128)          262144    ['leaky_re_lu_5[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 128)          512       ['conv2d_transpose_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 128)          0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)           131072    ['leaky_re_lu_6[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 64)           256       ['conv2d_transpose_3[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 64)           0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 64, 64, 3)            3075      ['leaky_re_lu_7[0][0]']       \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 729859 (2.78 MB)\n",
      "Trainable params: 728963 (2.78 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input = layers.Input(shape=(Z_DIM,))\n",
    "label_input = layers.Input(shape=(CLASSES,))\n",
    "x = layers.Concatenate(axis=-1)([generator_input, label_input])\n",
    "x = layers.Reshape((1, 1, Z_DIM + CLASSES))(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    128, kernel_size=4, strides=1, padding=\"valid\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    128, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    128, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(\n",
    "    64, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    ")(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "generator_output = layers.Conv2DTranspose(\n",
    "    CHANNELS, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\"\n",
    ")(x)\n",
    "generator = models.Model([generator_input, label_input], generator_output)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1bdf97-5952-4923-a81f-fece94821b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConditionalWGAN(models.Model):\n",
    "    def __init__(self, critic, generator, latent_dim, critic_steps, gp_weight):\n",
    "        super(ConditionalWGAN, self).__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.critic_steps = critic_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, c_optimizer, g_optimizer):\n",
    "        super(ConditionalWGAN, self).compile(run_eagerly=True)\n",
    "        self.c_optimizer = c_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.c_wass_loss_metric = metrics.Mean(name=\"c_wass_loss\")\n",
    "        self.c_gp_metric = metrics.Mean(name=\"c_gp\")\n",
    "        self.c_loss_metric = metrics.Mean(name=\"c_loss\")\n",
    "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.c_loss_metric,\n",
    "            self.c_wass_loss_metric,\n",
    "            self.c_gp_metric,\n",
    "            self.g_loss_metric,\n",
    "        ]\n",
    "\n",
    "    def gradient_penalty(\n",
    "        self, batch_size, real_images, fake_images, image_one_hot_labels\n",
    "    ):\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = self.critic(\n",
    "                [interpolated, image_one_hot_labels], training=True\n",
    "            )\n",
    "\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        image_one_hot_labels = one_hot_labels[:, None, None, :]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=IMAGE_SIZE, axis=1\n",
    "        )\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=IMAGE_SIZE, axis=2\n",
    "        )\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for i in range(self.critic_steps):\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.generator(\n",
    "                    [random_latent_vectors, one_hot_labels], training=True\n",
    "                )\n",
    "\n",
    "                fake_predictions = self.critic(\n",
    "                    [fake_images, image_one_hot_labels], training=True\n",
    "                )\n",
    "                real_predictions = self.critic(\n",
    "                    [real_images, image_one_hot_labels], training=True\n",
    "                )\n",
    "\n",
    "                c_wass_loss = tf.reduce_mean(fake_predictions) - tf.reduce_mean(\n",
    "                    real_predictions\n",
    "                )\n",
    "                c_gp = self.gradient_penalty(\n",
    "                    batch_size, real_images, fake_images, image_one_hot_labels\n",
    "                )\n",
    "                c_loss = c_wass_loss + c_gp * self.gp_weight\n",
    "\n",
    "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(\n",
    "                zip(c_gradient, self.critic.trainable_variables)\n",
    "            )\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(\n",
    "                [random_latent_vectors, one_hot_labels], training=True\n",
    "            )\n",
    "            fake_predictions = self.critic(\n",
    "                [fake_images, image_one_hot_labels], training=True\n",
    "            )\n",
    "            g_loss = -tf.reduce_mean(fake_predictions)\n",
    "\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        self.c_loss_metric.update_state(c_loss)\n",
    "        self.c_wass_loss_metric.update_state(c_wass_loss)\n",
    "        self.c_gp_metric.update_state(c_gp)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d9be79-8b32-4b28-8cfc-131e9c2b9535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a GAN\n",
    "cgan = ConditionalWGAN(\n",
    "    critic=critic,\n",
    "    generator=generator,\n",
    "    latent_dim=Z_DIM,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    gp_weight=GP_WEIGHT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "329ef2c9-acd5-4231-be15-119dbd8accbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    cgan.load_weights(\"/home/ec2-user/SageMaker/MachineLearning/checkpoint/checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a32fb-b2f0-4344-bbde-86a11e9f1fbe",
   "metadata": {},
   "source": [
    "# Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4dc58eb-756c-4902-85aa-8f77f0837f63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the GAN\n",
    "cgan.compile(\n",
    "    c_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    "    g_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cedeca1-2065-416b-b589-af0e9697ac78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"/home/ec2-user/SageMaker/MachineLearning/checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"/home/ec2-user/SageMaker/MachineLearning/logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        # 0 label\n",
    "        zero_label = np.repeat([[1, 0]], self.num_img, axis=0)\n",
    "        generated_images = self.model.generator(\n",
    "            [random_latent_vectors, zero_label]\n",
    "        )\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        #display(\n",
    "        #    generated_images,\n",
    "        #   save_to=\"./output/generated_img_%03d_label_0.png\" % (epoch),\n",
    "        #    cmap=None,\n",
    "        #)\n",
    "        for ima in generated_images:\n",
    "            plt.figure()\n",
    "            plt.imshow(ima)\n",
    "\n",
    "        # 1 label\n",
    "        one_label = np.repeat([[0, 1]], self.num_img, axis=0)\n",
    "        generated_images = self.model.generator(\n",
    "            [random_latent_vectors, one_label]\n",
    "        )\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        #display(\n",
    "        #     generated_images,\n",
    "        #     save_to=\"./output/generated_img_%03d_label_1.png\" % (epoch),\n",
    "        #    cmap=None,\n",
    "        #)\n",
    "        for ima in generated_images:\n",
    "            plt.figure()\n",
    "            plt.imshow(ima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89749ebb-d901-4ca6-8c05-43bf17bb91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from io import BytesIO\n",
    "#import PIL\n",
    "#from IPython.display import display, Image\n",
    "\n",
    "#def display_img_array(ima):\n",
    "#    im = PIL.Image.fromarray(ima)\n",
    "#    bio = BytesIO()\n",
    "#    im.save(bio, format='png')\n",
    "#    display(Image(bio.getvalue(), format='png'))\n",
    "\n",
    "#for ima in images:\n",
    "#    display_img_array(ima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2fb28f-a82d-4ddf-ba44-b27f799b2e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 5s 5s/step - c_loss: 7.2738 - c_wass_loss: -0.0485 - c_gp: 0.7322 - g_loss: 0.1023\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 5s 5s/step - c_loss: 7.0797 - c_wass_loss: -0.1739 - c_gp: 0.7254 - g_loss: 0.1437\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 5s 5s/step - c_loss: 6.8116 - c_wass_loss: -0.3165 - c_gp: 0.7128 - g_loss: 0.1956\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 5s 5s/step - c_loss: 6.4537 - c_wass_loss: -0.4901 - c_gp: 0.6944 - g_loss: 0.2676\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 5s 5s/step - c_loss: 5.9882 - c_wass_loss: -0.7574 - c_gp: 0.6746 - g_loss: 0.4007\n"
     ]
    }
   ],
   "source": [
    "history = cgan.fit(\n",
    "    train,\n",
    "    epochs= 5, #EPOCHS * 100\n",
    "    steps_per_epoch=1,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        #ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afaf90f-b8b0-45bd-9c42-f09cc5bb65a2",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd88843c-8978-4fc4-af6e-444ce59a4055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# 0 label\n",
    "z_sample = np.random.normal(size=(10, Z_DIM))\n",
    "class_label = np.repeat([[1, 0]], 10, axis=0)\n",
    "imgs = cgan.generator.predict([z_sample, class_label])\n",
    "#display(imgs, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be22d584-9193-4087-b559-aa766f5e7d53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# 1 label\n",
    "z_sample = np.random.normal(size=(10, Z_DIM))\n",
    "class_label = np.repeat([[0, 1]], 10, axis=0)\n",
    "imgs = cgan.generator.predict([z_sample, class_label])\n",
    "#display(imgs, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b592456-0235-4ee9-9e7a-531da6d9bf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
